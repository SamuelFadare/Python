{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Modelling and Predictions\n",
    "\n",
    "Today we will learn how to practically tune a classifier by using cross-validation and a hold-out test set. Finally, there will be a competition for you to hone your skills.\n",
    "\n",
    "Let's dive right into it. \n",
    "\n",
    "## Today's idioms\n",
    "### Training a naive bayes classifier in Scikit-learn\n",
    "Scikit-learn comes with various implementations of the Naive Bayes classifier. The \"standard\" one is the Gaussian variant, which assumes the data has a normal distribution (although it works reasonably well for cases where this assumption doesn't quite hold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has shape (150, 4), targets have shape (150,).\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets as data\n",
    "\n",
    "X, y  = data.load_iris(return_X_y=True)  # returns data to be used in estimator\n",
    "# X is the data, y are the targets:\n",
    "print(\"data has shape {}, targets have shape {}.\".format(X.shape, y.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate and train/fit the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.naive_bayes as nb\n",
    "gnb = nb.GaussianNB() # instantiates a Gaussian Naive Bayes object\n",
    "gnb.fit(X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gnb.predict(X=X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the targets 0, 1, 2 stand for *setosa*, *virginica* and *versicolor*. It looks like there are a few errors though! This is how the real targets look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, -1,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y - y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be all zeros if the prediction was correct. Let's compute the accuracy, i.e. the percetage of correct predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y != y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a more general way to compare classifications. Think about when these two ways produce different results and why this one is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 96.00%\n"
     ]
    }
   ],
   "source": [
    "fraction_wrong = np.sum(y != y_pred)/len(y) # how many nonzeros, divided by total number\n",
    "acc = 100*(1-fraction_wrong)\n",
    "print(\"accuracy is {:.2f}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96 percent correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see what an SVM can do.\n",
    "\n",
    "### Training an SVM in scikit-learn\n",
    "\n",
    "We use a linear SVM with a linear kernel. The process is the standard one. First we instantiate the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we fit and predict: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X=X, y=y)\n",
    "y_pred = svc.predict(X=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we compute the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 99.33%\n"
     ]
    }
   ],
   "source": [
    "acc = 100*(1-np.sum(y != y_pred)/len(y))\n",
    "print(\"accuracy is {:.2f}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hey, that's already substantially better than Naive Bayes! Later you can try to get even better by tuning the parameters.\n",
    "\n",
    "But first let's try a Multi-Layer Neural Network.\n",
    "\n",
    "### Training a Multi-Layer Neural Network in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now you should have gotten the gist of how to instantiate, train and predict using a classifier. The process is standard in `sklearn`, that means you can use it with any estimator/classifier. \n",
    "\n",
    "Here we lump it all together in one cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 98.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neural_network as nn\n",
    "mlp = nn.MLPClassifier(random_state=1, max_iter=1000)  #instantiates a Multi-Layer Perceptron (a specific Multi-Layer Neural Network)\n",
    "mlp.fit(X=X, y=y)\n",
    "y_pred = mlp.predict(X=X)\n",
    "acc = 100*(1-np.sum(y != y_pred)/len(y))\n",
    "print(\"accuracy is {:.2f}%\".format(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, a warning! It complains that the training process of the network has not yet converged, because the maximum iterations the algorithm is instructed to perform (by default) have been reached. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - fix the warning\n",
    "Check the documentation of `sklearn.neural_network.MLPClassifier` to find the parameter that controls the maximum number of iterations. Set it to a higher value until the warning goes away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MLPClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the code below to make the warning disappear:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the code, we have to change the maximum number of iterations from default to a much more larger value. To solve this task, I am increasing the number of maximum iterations to 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 98.00%\n"
     ]
    }
   ],
   "source": [
    "mlp = nn.MLPClassifier(random_state=1, max_iter=1000)  #here you need to add the parameter\n",
    "mlp.fit(X=X, y=y)\n",
    "y_pred = mlp.predict(X=X)\n",
    "acc = 100*(1-np.sum(y != y_pred)/len(y))\n",
    "print(\"accuracy is {:.2f}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation \n",
    "\n",
    "Up to now we trained the classifier on all available data. It is very likely that we are overestimating the ability of the trained classifier to predict unseen data. But since we don't *have* unseen data, how can we test how well the classifier might generalise?\n",
    "\n",
    "The solution is **Cross-validation**. In a nutshell, it means you split your data into several equal-sized chunks, so-called folds. You keep one fold out and train the classifier on the remaining chunks. Repeat until each fold has been held out once. Then compute the accuracy on the held-out folds. \n",
    "\n",
    "The scikit-learn online documentation has a [good overview](https://scikit-learn.org/stable/modules/cross_validation.html) I recommend to read should you feel you need a refresher.  \n",
    "\n",
    "The cross-calidation module is straightforward to use. It does the data splitting for you and loops over the fit/predict cycle. All you need to provide is an instance of a classifier.\n",
    "\n",
    "Below is an example of cross-validation with an SVM with a linear kernel and `C=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.model_selection as ms\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = ms.cross_val_score(clf, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the mean score and the 95% confidence interval (i.e., two standard deviations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning: some examples\n",
    "\n",
    "### Creating a hold-out data set: test-training split\n",
    "When tuning parameters, it is advisable to create a hold-out set that you don't touch until your parameter tuning campaign is finished. \n",
    "\n",
    "You can create multiple candidate tuning sets and use the hold-out set at the very end in order to find the model that generalises best.\n",
    "\n",
    "Scikit-learn provides the `test_train_split` function that provides this functionality. The below example creates a 40% test/training split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ms.train_test_split(\n",
    "     X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks fine. \n",
    "\n",
    "In the remainder, we will not be touching the test set until we have completed the parameter optimisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM tuning\n",
    "\n",
    "Tunable parameters for soft-margin SVMs include:\n",
    " * $C$, a positive, numerical value, that controls the penalty for misclassifications.\n",
    " * the kernel choice. Sensible beginner choices in scikit-learn are `linear`, `poly`, `rbf`, `sigmoid`. These come with different tuning options. \n",
    "\n",
    "#### Stuck? Read the docs!\n",
    "Refer to the documentation on [support vector classification](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) for more info.\n",
    "\n",
    "There is also an excellent [SVM user guide](https://scikit-learn.org/stable/modules/svm.html) available in the on-line documentation of scikit-learn. Read \n",
    "\n",
    "### Task 2: Hands-on tuning\n",
    "Use the code below to try out a few parameter settings. Note that it uses cross-validation, using the previously generated training data from the `train_test_split` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9889 (+/- 0.0444)\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC(kernel='linear', C=1)\n",
    "scores = ms.cross_val_score(svc, X_train, y_train, cv=5)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2 SOLUTION\n",
    "Trying our new parameter settings, and using several kernel choices such as linear, poly, rbf, and sigmoid. We can choose our best combination from trying various parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9889 (+/- 0.0444)\n"
     ]
    }
   ],
   "source": [
    "#changing our c value to 7 while our kernel remains linear, we have\n",
    "svc_1 = svm.SVC(kernel='linear', C=7)\n",
    "scores = ms.cross_val_score(svc_1, X_train, y_train, cv=5)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
    "# This simply implies that values from 1 to 7 are a good combination for our svm when kernel is linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9889 (+/- 0.0444)\n"
     ]
    }
   ],
   "source": [
    "#changing our c value to 1 gives a good combination when kernel is poly\n",
    "svc_2 = svm.SVC(kernel='poly', C=1)\n",
    "scores = ms.cross_val_score(svc_2, X_train, y_train, cv=5)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9889 (+/- 0.0444)\n"
     ]
    }
   ],
   "source": [
    "#changing our c value to 8 gives a good combination when kernel is rbf\n",
    "svc_3 = svm.SVC(kernel='rbf', C=8)\n",
    "scores = ms.cross_val_score(svc_3, X_train, y_train, cv=5)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3778 (+/- 0.0444)\n"
     ]
    }
   ],
   "source": [
    "#changing our c value to 1 gives a good combination when kernel is rbf\n",
    "svc_4 = svm.SVC(kernel='sigmoid', C=1)\n",
    "scores = ms.cross_val_score(svc_4, X_train, y_train, cv=5)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2 SOLUTION SUMMARY\n",
    "Trying a parameter setting of C = 7, and kernel = linear we have our accuracy value is nearest to 1 (0.9889).\n",
    "\n",
    "Trying a parameter setting of C = 1, and kernel = poly we have our accuracy value is nearest to 1 (0.9889). \n",
    "\n",
    "Trying a parameter setting of C = 8, and kernel = rbf we have our accuracy value is nearest to 1 (0.9889). \n",
    "\n",
    "Trying a parameter setting of C = 1, and kernel = sigmoid we have our accuracy value is farther to 1 (0.3778).\n",
    "\n",
    "**A good combination of C and kernel choice would be svc_1, where C = 7, and kernel = linear**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9889 (+/- 0.0444)\n"
     ]
    }
   ],
   "source": [
    "#Equating our choice of good combination to svc \n",
    "svc_1 = svm.SVC(kernel='linear', C=1)\n",
    "scores = ms.cross_val_score(svc_3, X_train, y_train, cv=5)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have found a good combination of $C$ and kernel choice, execute the code below to store that classifier in the variable `best_svm`, and proceed to the next part, \"Neural Networks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm = svc_1\n",
    "best_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks\n",
    "\n",
    "Neural networks have tons of parameters to tune, and they are usually much more difficult to understand than SVM's parameters. Have a look at the [MLPClassifier on-line documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) to get a glimpse. Note that these are not even deep networks, for which the number of parameters multiply!\n",
    "\n",
    "The most common tuning parameters are.\n",
    "* `hidden_layer_sizes`: the number of the number of hidden layers and the neurons therein. Examples:\n",
    "    * `hidden_layer_sizes=(100,)` would create a single hidden layer with 100 neurons (the default)\n",
    "    * `hidden_layer_sizes=(20,10)` would create two hidden layers, the first with 20 and the second with 10 neurons. \n",
    "* `activation`: the transfer function. The default is `relu`, the \"REctifying Linear Unit\", but other choices are worth a try, e.g. the signmoidal functions `sigmoid`, `tanh`, or `logistic`.\n",
    "* `learning_rate`: The default is constant, but for complicated data sets it can help to set it to other options. Check the documentation for an explanation. \n",
    "\n",
    "The [MLPClassifier on-line documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) states a useful tweak to the `solver` parameter:\n",
    "> The default solver ‘adam’ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, ‘lbfgs’ can converge faster and perform better.\n",
    "\n",
    "We will therefore use the 'lbfgs' solver. \n",
    "\n",
    "* best MLP should be stored in variable `best_mlp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9778 (+/- 0.0544)\n"
     ]
    }
   ],
   "source": [
    "mlp = nn.MLPClassifier(hidden_layer_sizes=(100,10), \n",
    "                       activation='relu',\n",
    "                       learning_rate='constant',\n",
    "                       solver='lbfgs',\n",
    "                      max_iter= 1000)\n",
    "scores = ms.cross_val_score(mlp, X_train, y_train,cv=5)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRYING OUT SEVERAL ACTIVATION FUNCTIONS ON OUR MLP TO KNOW THE BEST FIT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9556 (+/- 0.0831)\n"
     ]
    }
   ],
   "source": [
    "#using activation as tanh\n",
    "mlp_2 = nn.MLPClassifier(hidden_layer_sizes=(100,10), \n",
    "                       activation='tanh',\n",
    "                       learning_rate='constant',\n",
    "                       solver='lbfgs')\n",
    "scores = ms.cross_val_score(mlp, X_train, y_train,cv=5)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9667 (+/- 0.0544)\n"
     ]
    }
   ],
   "source": [
    "#using activation as Logistic\n",
    "mlp_3 = nn.MLPClassifier(hidden_layer_sizes=(100,10), \n",
    "                       activation='Logistic',\n",
    "                       learning_rate='constant',\n",
    "                       solver='lbfgs',\n",
    "                        max_iter= 1000)\n",
    "scores = ms.cross_val_score(mlp, X_train, y_train,cv=5)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9778 (+/- 0.0544)\n"
     ]
    }
   ],
   "source": [
    "#using activation as sigmoid\n",
    "mlp_2 = nn.MLPClassifier(hidden_layer_sizes=(100,10), \n",
    "                       activation='sigmoid',\n",
    "                       learning_rate='constant',\n",
    "                       solver='lbfgs')\n",
    "scores = ms.cross_val_score(mlp, X_train, y_train,cv=5)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KINDLY NOTE: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FROM TESTING OUR ACTIVARTION FUNCTIONS, WE CAN SEE THAT OUR BEST FIT MLP ARE RELU, AND TANH, AS THEY BOTH GIVE AN ACCURACY VALUE OF 0.9667 (+/- 0.0544), WHILE THE SIGMOID ACTIVATION GIVES THE LOWEST ACCURACY. THEREFORE WE WOULD USE RELU AS OUR BEST ACTIVATOR (MLP).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above we store the best network for evaluation of the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the best classfier?\n",
    "Now our hold-out dataset comes into play. Let's evaluate the best MLP and the best SVM on the hold-out set.\n",
    "\n",
    "Verify that the best_svm has the correct parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train it on the entire training set and evaluate it on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 96.6667%\n"
     ]
    }
   ],
   "source": [
    "# SVM \n",
    "best_svm.fit(X=X_train, y=y_train)\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "acc = 100*(1-np.sum(y_test != y_pred_svm)/len(y_test))\n",
    "print(\"accuracy is {:.4f}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for the Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 10), max_iter=1000, solver='lbfgs')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 96.6667%\n"
     ]
    }
   ],
   "source": [
    "# MLP \n",
    "best_mlp.fit(X=X_train, y=y_train)\n",
    "y_pred_mlp = best_mlp.predict(X_test)\n",
    "acc = 100*(1-np.sum(y_test != y_pred_mlp)/len(y_test))\n",
    "print(\"accuracy is {:.4f}%\".format(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Repeat with Naïve Bayes classifier\n",
    "Repeat the training procedure with the Naive Bayes algorithm. Copy necessary code from above and adapt to use the training set for training and the testing set for prediction. How does it compare to the MLP and SVM classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 3 SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating the training procedure with the Naive Bayes algorithm we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = nb.GaussianNB() # instantiates a Gaussian Naive Bayes object\n",
    "gnb.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = gnb.predict(X=X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 0, 1, 2, 1,\n",
       "       0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2,\n",
       "       2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2, 0, 0, 2, 0,\n",
       "       2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 2, 1,\n",
       "       2, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y != y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 97.78%\n"
     ]
    }
   ],
   "source": [
    "fraction_wrong = np.sum(y != y_pred_train)/len(y) # how many nonzeros, divided by total number\n",
    "acc = 100*(1-fraction_wrong)\n",
    "print(\"accuracy is {:.2f}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating the testing procedure with the Naive Bayes algorithm we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = nb.GaussianNB() # instantiates a Gaussian Naive Bayes object\n",
    "gnb.fit(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 2, 1, 1, 2, 0, 2, 0,\n",
       "       0, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = gnb.predict(X=X_test)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 1, 1, 1, 2, 0, 2, 0,\n",
       "       0, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y != y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 95.00%\n"
     ]
    }
   ],
   "source": [
    "fraction_wrong = np.sum(y != y_pred_test)/len(y) # how many nonzeros, divided by total number\n",
    "acc = 100*(1-fraction_wrong)\n",
    "print(\"accuracy is {:.2f}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBSERVATION AND COMPARISON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After observing our values for MLP, SVM, Naive Bayes Algorithm for training, and Naive Bayes Algorithm for testing, I got the following accuracy percentages:\n",
    "\n",
    "**MLP ACCURACY IS 96.6667%**\n",
    "\n",
    "**SVM ACCURACY IS 96.6667**\n",
    "\n",
    "**NAIVE BAYES ALGORITHM FOR TRAINING IS 97.78%**\n",
    "\n",
    "**NAIVE BAYES ALGORITHM FOR TESTING IS 95.00%**\n",
    "\n",
    "We can see that Naive Bayes Algorithm for Training has the most accuracy among all classifiers, then MLP and SVM has a higher accuracy than the Naive Bayes Algorithm for Testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
