{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Bw1uPwXVRwqY"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Fsu4ibnaRwqZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwTyvJnGRwqb",
    "outputId": "57f0aa48-f244-4394-fb6d-0b6af5518fe2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, load_model, model_from_json\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "djQPEwaPRwqc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tZaC-721SQvA",
    "outputId": "bdc47a91-a142-4463-aa9d-3631fd936fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aix360 in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
      "Requirement already satisfied: cvxpy in /usr/local/lib/python3.7/dist-packages (from aix360) (1.0.31)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.1.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from aix360) (1.3.5)\n",
      "Requirement already satisfied: shap==0.34.0 in /usr/local/lib/python3.7/dist-packages (from aix360) (0.34.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from aix360) (1.21.5)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.4.1)\n",
      "Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from aix360) (0.17.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.0.2)\n",
      "Requirement already satisfied: xgboost==1.0.2 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.0.2)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from aix360) (0.11.1+cu111)\n",
      "Requirement already satisfied: cvxopt in /usr/local/lib/python3.7/dist-packages (from aix360) (1.2.7)\n",
      "Requirement already satisfied: qpsolvers in /usr/local/lib/python3.7/dist-packages (from aix360) (1.8.1)\n",
      "Requirement already satisfied: xport in /usr/local/lib/python3.7/dist-packages (from aix360) (3.6.1)\n",
      "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.7/dist-packages (from aix360) (2.3.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from aix360) (2.23.0)\n",
      "Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.7/dist-packages (from aix360) (1.14.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aix360) (3.2.2)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from aix360) (0.18.3)\n",
      "Requirement already satisfied: Pygments in /usr/local/lib/python3.7/dist-packages (from aix360) (2.6.1)\n",
      "Requirement already satisfied: lime==0.1.1.37 in /usr/local/lib/python3.7/dist-packages (from aix360) (0.1.1.37)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from aix360) (1.10.0+cu111)\n",
      "Requirement already satisfied: bleach>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from aix360) (4.1.0)\n",
      "Requirement already satisfied: Image in /usr/local/lib/python3.7/dist-packages (from aix360) (1.5.33)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (1.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (3.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1->aix360) (1.15.0)\n",
      "Requirement already satisfied: progressbar in /usr/local/lib/python3.7/dist-packages (from lime==0.1.1.37->aix360) (2.5)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap==0.34.0->aix360) (4.63.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.37.1)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.44.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.14.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.1.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (0.5.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14->aix360) (3.17.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach>=2.1.0->aix360) (21.3)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach>=2.1.0->aix360) (0.5.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (2.4.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (7.1.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (2.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (1.3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->aix360) (2021.11.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aix360) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aix360) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aix360) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aix360) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->aix360) (3.10.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.2->aix360) (3.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (57.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (3.3.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14->aix360) (3.7.0)\n",
      "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from cvxpy->aix360) (3.2.0)\n",
      "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy->aix360) (0.6.2.post0)\n",
      "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy->aix360) (2.0.10)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from cvxpy->aix360) (0.70.12.2)\n",
      "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy->aix360) (0.1.5.post0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.1->aix360) (1.5.2)\n",
      "Requirement already satisfied: django in /usr/local/lib/python3.7/dist-packages (from Image->aix360) (3.2.12)\n",
      "Requirement already satisfied: sqlparse>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from django->Image->aix360) (0.4.2)\n",
      "Requirement already satisfied: asgiref<4,>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from django->Image->aix360) (3.5.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from django->Image->aix360) (2018.9)\n",
      "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.7/dist-packages (from multiprocess->cvxpy->aix360) (0.3.4)\n",
      "Requirement already satisfied: quadprog>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from qpsolvers->aix360) (0.1.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->aix360) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->aix360) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->aix360) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->aix360) (2021.10.8)\n",
      "Requirement already satisfied: click>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from xport->aix360) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install aix360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Cpj_kfWxRwqc"
   },
   "outputs": [],
   "source": [
    "from aix360.algorithms.contrastive import CEMExplainer, KerasClassifier\n",
    "from aix360.algorithms.protodash import ProtodashExplainer\n",
    "from aix360.datasets.heloc_dataset import HELOCDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHucQKxxVA9v"
   },
   "source": [
    "If you see an error message about the missing data, then you must upload the heloc_data.cvs file into the folder /usr/local/lib/python3.7/dist-packages/aix360/datasets/../data/heloc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cEAVi-peRwqd",
    "outputId": "8ca9253c-4314-4e4d-849e-c4a5b440959e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Heloc dataset:  /usr/local/lib/python3.7/dist-packages/aix360/datasets/../data/heloc_data/heloc_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "heloc = HELOCDataset()\n",
    "df = heloc.dataframe()\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 24)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TLXESaBjXQoK"
   },
   "source": [
    "Task 1: Display the first 10, or so, of the data rows from the imported file..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpBgSHyRXsKG"
   },
   "source": [
    "Task 2: Display the numbers of \"Good\" and \"Bad\" applicants..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKcfx8pnYEDF"
   },
   "source": [
    "Task 3: Create a histogram to observe the distribution of values for certain features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gx9YAUZxPqBA"
   },
   "source": [
    "**TASK 1 SOLUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "laIyAVnfPyor",
    "outputId": "50b55d47-f62c-44e9-ba7d-a89a26263f12"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5acb5339-b9a6-4ef6-87f2-72f86cfe397b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExternalRiskEstimate</th>\n",
       "      <td>55</td>\n",
       "      <td>61</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>81</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceOldestTradeOpen</th>\n",
       "      <td>144</td>\n",
       "      <td>58</td>\n",
       "      <td>66</td>\n",
       "      <td>169</td>\n",
       "      <td>333</td>\n",
       "      <td>137</td>\n",
       "      <td>88</td>\n",
       "      <td>148</td>\n",
       "      <td>324</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceMostRecentTradeOpen</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AverageMInFile</th>\n",
       "      <td>84</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>73</td>\n",
       "      <td>132</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>65</td>\n",
       "      <td>138</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumSatisfactoryTrades</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTrades60Ever2DerogPubRec</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTrades90Ever2DerogPubRec</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentTradesNeverDelq</th>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceMostRecentDelq</th>\n",
       "      <td>2</td>\n",
       "      <td>-7</td>\n",
       "      <td>-7</td>\n",
       "      <td>76</td>\n",
       "      <td>-7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDelq2PublicRecLast12M</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDelqEver</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTotalTrades</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTradesOpeninLast12M</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentInstallTrades</th>\n",
       "      <td>43</td>\n",
       "      <td>67</td>\n",
       "      <td>44</td>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceMostRecentInqexcl7days</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInqLast6M</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInqLast6Mexcl7days</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetFractionRevolvingBurden</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>62</td>\n",
       "      <td>89</td>\n",
       "      <td>28</td>\n",
       "      <td>68</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetFractionInstallBurden</th>\n",
       "      <td>-8</td>\n",
       "      <td>-8</td>\n",
       "      <td>66</td>\n",
       "      <td>83</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>-8</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumRevolvingTradesWBalance</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInstallTradesWBalance</th>\n",
       "      <td>1</td>\n",
       "      <td>-8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
       "      <td>1</td>\n",
       "      <td>-8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentTradesWBalance</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>91</td>\n",
       "      <td>80</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>90</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RiskPerformance</th>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5acb5339-b9a6-4ef6-87f2-72f86cfe397b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5acb5339-b9a6-4ef6-87f2-72f86cfe397b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5acb5339-b9a6-4ef6-87f2-72f86cfe397b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                      0    1    2    3    4    5     6     7    8    9\n",
       "ExternalRiskEstimate                 55   61   67   66   81   59    54    68   59   61\n",
       "MSinceOldestTradeOpen               144   58   66  169  333  137    88   148  324   79\n",
       "MSinceMostRecentTradeOpen             4   15    5    1   27   11     7     7    2    4\n",
       "AverageMInFile                       84   41   24   73  132   78    37    65  138   36\n",
       "NumSatisfactoryTrades                20    2    9   28   12   31    25    17   24   19\n",
       "NumTrades60Ever2DerogPubRec           3    4    0    1    0    0     0     0    0    0\n",
       "NumTrades90Ever2DerogPubRec           0    4    0    1    0    0     0     0    0    0\n",
       "PercentTradesNeverDelq               83  100  100   93  100   91    92    83   85   95\n",
       "MSinceMostRecentDelq                  2   -7   -7   76   -7    1     9    31    5    5\n",
       "MaxDelq2PublicRecLast12M              3    0    7    6    7    4     4     6    4    4\n",
       "MaxDelqEver                           5    8    8    6    8    6     6     6    6    6\n",
       "NumTotalTrades                       23    7    9   30   12   32    26    18   27   19\n",
       "NumTradesOpeninLast12M                1    0    4    3    0    1     3     1    1    3\n",
       "PercentInstallTrades                 43   67   44   57   25   47    58    44   26   26\n",
       "MSinceMostRecentInqexcl7days          0    0    0    0    0    0     0     0    0    0\n",
       "NumInqLast6M                          0    0    4    5    1    0     4     0    1    6\n",
       "NumInqLast6Mexcl7days                 0    0    4    4    1    0     4     0    1    6\n",
       "NetFractionRevolvingBurden           33    0   53   72   51   62    89    28   68   31\n",
       "NetFractionInstallBurden             -8   -8   66   83   89   93    76    48   -8   86\n",
       "NumRevolvingTradesWBalance            8    0    4    6    3   12     7     2    7    5\n",
       "NumInstallTradesWBalance              1   -8    2    4    1    4     7     2    1    3\n",
       "NumBank2NatlTradesWHighUtilization    1   -8    1    3    0    3     2     2    3    1\n",
       "PercentTradesWBalance                69    0   86   91   80   94   100    40   90   62\n",
       "RiskPerformance                     Bad  Bad  Bad  Bad  Bad  Bad  Good  Good  Bad  Bad"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxsTzuhxQIbo"
   },
   "source": [
    "**TASK 2 SOLUTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVEcKjscQzeb"
   },
   "source": [
    "Displaying the number of good and bad applicants we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNgeaJe9QNtP",
    "outputId": "1eff8745-f279-4d57-bcca-c1380ccb2dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"Good\" applicants: 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of \\\"Good\\\" applicants:\", np.sum(df['RiskPerformance']=='Good'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B0lGsi0Rz8W"
   },
   "source": [
    "Displaying the number of bad applicants, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AN77NACPQh2_",
    "outputId": "edfbc6d0-cb63-4ae2-de91-748f1b2265e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"Bad\" applicants: 5459\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of \\\"Bad\\\" applicants:\", np.sum(df['RiskPerformance']=='Bad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hI8R-wQR816"
   },
   "source": [
    "**TASK 3 SOLUTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rT6p3NOqSNV0"
   },
   "source": [
    "Displaying histogram of certain attributes to show variations of values, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "RkzsXhufSDrk",
    "outputId": "f731edf0-b261-4352-ce20-33455e03c690"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f8fb2a24b90>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(column=['ExternalRiskEstimate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "UIdvSnBhSDus",
    "outputId": "f0841f06-acd9-4b94-e3b2-c27d456eb53a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f8fb293c790>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(column=['MSinceOldestTradeOpen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vkphyLgERwqj"
   },
   "outputs": [],
   "source": [
    "(Data, x_train, x_test, y_train_b, y_test_b) = heloc.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iBjRqqoYRwqk"
   },
   "outputs": [],
   "source": [
    "Z = np.vstack((x_train, x_test))\n",
    "Zmax = np.max(Z, axis=0)\n",
    "Zmin = np.min(Z, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2guOq7U4Rwqk",
    "outputId": "d33df3e9-5668-4bc2-bc67-0d3b090e73f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 4 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(Zmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lpfyin2iRwql",
    "outputId": "0623bee6-251c-4c35-e3cc-5c701c7f0de7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 94 803 383 383  79  19  19 100  83   9   8 104  19 100  24  66  66 232\n",
      " 471  32  23  18 100]\n"
     ]
    }
   ],
   "source": [
    "print(Zmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oy2qFqBYhaP"
   },
   "source": [
    "Task 4 (for advanced students): Normalise the training and test data such that all values are in the range [-0.5, 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fpp1MQXEVi2F"
   },
   "source": [
    "**TASK 4 SOLUTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Nic1NhPcEyd"
   },
   "source": [
    "Normalizing the training and test data such that all values are in the range -0.5 and 0.5, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DZW9z_3_Vedv"
   },
   "outputs": [],
   "source": [
    "def normalize(V):\n",
    "    VN = (V - Zmin)/(Zmax - Zmin)\n",
    "    VN = VN - 0.5\n",
    "    return(VN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGtrR1j_Vh4n",
    "outputId": "5279b3ee-4c11-4afd-e8e0-82650130ec19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12765957 -0.29078456 -0.4921671  -0.41029024 -0.23417722 -0.5\n",
      "  -0.5         0.5        -0.5         0.27777778  0.5        -0.29807692\n",
      "   0.13157895 -0.12       -0.5        -0.48484848 -0.48484848 -0.13362069\n",
      "  -0.3089172  -0.1875     -0.2826087  -0.27777778  0.44      ]]\n"
     ]
    }
   ],
   "source": [
    "print(normalize(x_train[2:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "IN2WojRoRwqm"
   },
   "outputs": [],
   "source": [
    "N = normalize(Z)\n",
    "xn_train = N[0:x_train.shape[0], :]\n",
    "xn_test  = N[x_train.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2kaac1hVRwqn"
   },
   "outputs": [],
   "source": [
    "def nn_small():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=23, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(2, kernel_initializer='normal'))    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "uJr1QClvRwqo"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1) \n",
    "tf.set_random_seed(2) \n",
    "\n",
    "class_names = ['Bad', 'Good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "U9i5CGEPRwqo"
   },
   "outputs": [],
   "source": [
    "def fn(correct, predicted):\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(labels=correct, logits=predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0AuUWDZ3Rwqw",
    "outputId": "d24ca730-261e-4c4d-a0d7-0ece8b13ed63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-ea7df5a704d6>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                240       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 262\n",
      "Trainable params: 262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn = nn_small()\n",
    "nn.compile(loss=fn, optimizer='adam', metrics=['accuracy'])\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QtstmDPIRwqw",
    "outputId": "6a27bb2a-7823-4748-a635-2a7829fe5693"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/500\n",
      "7403/7403 [==============================] - 0s 53us/step - loss: 0.6878 - accuracy: 0.5346\n",
      "Epoch 2/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.6641 - accuracy: 0.6414\n",
      "Epoch 3/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.6244 - accuracy: 0.6996\n",
      "Epoch 4/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5931 - accuracy: 0.7093\n",
      "Epoch 5/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5766 - accuracy: 0.7130\n",
      "Epoch 6/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5679 - accuracy: 0.7196\n",
      "Epoch 7/500\n",
      "7403/7403 [==============================] - 0s 9us/step - loss: 0.5627 - accuracy: 0.7220\n",
      "Epoch 8/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5591 - accuracy: 0.7254\n",
      "Epoch 9/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5566 - accuracy: 0.7248\n",
      "Epoch 10/500\n",
      "7403/7403 [==============================] - 0s 9us/step - loss: 0.5546 - accuracy: 0.7263\n",
      "Epoch 11/500\n",
      "7403/7403 [==============================] - 0s 9us/step - loss: 0.5531 - accuracy: 0.7278\n",
      "Epoch 12/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5519 - accuracy: 0.7285\n",
      "Epoch 13/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5509 - accuracy: 0.7279\n",
      "Epoch 14/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5501 - accuracy: 0.7282\n",
      "Epoch 15/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5494 - accuracy: 0.7297\n",
      "Epoch 16/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5487 - accuracy: 0.7306\n",
      "Epoch 17/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5482 - accuracy: 0.7313\n",
      "Epoch 18/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5477 - accuracy: 0.7315\n",
      "Epoch 19/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5473 - accuracy: 0.7316\n",
      "Epoch 20/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5469 - accuracy: 0.7313\n",
      "Epoch 21/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5466 - accuracy: 0.7311\n",
      "Epoch 22/500\n",
      "7403/7403 [==============================] - 0s 9us/step - loss: 0.5463 - accuracy: 0.7312\n",
      "Epoch 23/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5460 - accuracy: 0.7312\n",
      "Epoch 24/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5458 - accuracy: 0.7316\n",
      "Epoch 25/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5455 - accuracy: 0.7313\n",
      "Epoch 26/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5453 - accuracy: 0.7313\n",
      "Epoch 27/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5451 - accuracy: 0.7320\n",
      "Epoch 28/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5449 - accuracy: 0.7319\n",
      "Epoch 29/500\n",
      "7403/7403 [==============================] - 0s 9us/step - loss: 0.5448 - accuracy: 0.7319\n",
      "Epoch 30/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5446 - accuracy: 0.7323\n",
      "Epoch 31/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5444 - accuracy: 0.7324\n",
      "Epoch 32/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5442 - accuracy: 0.7334\n",
      "Epoch 33/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5441 - accuracy: 0.7335\n",
      "Epoch 34/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5439 - accuracy: 0.7336\n",
      "Epoch 35/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5438 - accuracy: 0.7335\n",
      "Epoch 36/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5436 - accuracy: 0.7336\n",
      "Epoch 37/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5435 - accuracy: 0.7340\n",
      "Epoch 38/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5434 - accuracy: 0.7339\n",
      "Epoch 39/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5433 - accuracy: 0.7339\n",
      "Epoch 40/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5432 - accuracy: 0.7331\n",
      "Epoch 41/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5431 - accuracy: 0.7329\n",
      "Epoch 42/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5430 - accuracy: 0.7334\n",
      "Epoch 43/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5429 - accuracy: 0.7335\n",
      "Epoch 44/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5428 - accuracy: 0.7338\n",
      "Epoch 45/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5427 - accuracy: 0.7339\n",
      "Epoch 46/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5426 - accuracy: 0.7342\n",
      "Epoch 47/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5425 - accuracy: 0.7343\n",
      "Epoch 48/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5425 - accuracy: 0.7343\n",
      "Epoch 49/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5424 - accuracy: 0.7339\n",
      "Epoch 50/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5423 - accuracy: 0.7340\n",
      "Epoch 51/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5422 - accuracy: 0.7339\n",
      "Epoch 52/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5422 - accuracy: 0.7339\n",
      "Epoch 53/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5421 - accuracy: 0.7336\n",
      "Epoch 54/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5421 - accuracy: 0.7339\n",
      "Epoch 55/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5420 - accuracy: 0.7338\n",
      "Epoch 56/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5419 - accuracy: 0.7339\n",
      "Epoch 57/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5419 - accuracy: 0.7339\n",
      "Epoch 58/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5418 - accuracy: 0.7342\n",
      "Epoch 59/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5417 - accuracy: 0.7347\n",
      "Epoch 60/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5417 - accuracy: 0.7347\n",
      "Epoch 61/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5416 - accuracy: 0.7350\n",
      "Epoch 62/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5416 - accuracy: 0.7347\n",
      "Epoch 63/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5415 - accuracy: 0.7350\n",
      "Epoch 64/500\n",
      "7403/7403 [==============================] - 0s 9us/step - loss: 0.5415 - accuracy: 0.7344\n",
      "Epoch 65/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5414 - accuracy: 0.7346\n",
      "Epoch 66/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5414 - accuracy: 0.7344\n",
      "Epoch 67/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5413 - accuracy: 0.7346\n",
      "Epoch 68/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5413 - accuracy: 0.7352\n",
      "Epoch 69/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5412 - accuracy: 0.7351\n",
      "Epoch 70/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5412 - accuracy: 0.7350\n",
      "Epoch 71/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5411 - accuracy: 0.7348\n",
      "Epoch 72/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5411 - accuracy: 0.7346\n",
      "Epoch 73/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5410 - accuracy: 0.7347\n",
      "Epoch 74/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5409 - accuracy: 0.7347\n",
      "Epoch 75/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5409 - accuracy: 0.7346\n",
      "Epoch 76/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5408 - accuracy: 0.7344\n",
      "Epoch 77/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5408 - accuracy: 0.7338\n",
      "Epoch 78/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5407 - accuracy: 0.7338\n",
      "Epoch 79/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5406 - accuracy: 0.7334\n",
      "Epoch 80/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5406 - accuracy: 0.7335\n",
      "Epoch 81/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5405 - accuracy: 0.7336\n",
      "Epoch 82/500\n",
      "7403/7403 [==============================] - 0s 9us/step - loss: 0.5405 - accuracy: 0.7338\n",
      "Epoch 83/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5404 - accuracy: 0.7336\n",
      "Epoch 84/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5404 - accuracy: 0.7335\n",
      "Epoch 85/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5403 - accuracy: 0.7331\n",
      "Epoch 86/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5403 - accuracy: 0.7331\n",
      "Epoch 87/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5402 - accuracy: 0.7332\n",
      "Epoch 88/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5402 - accuracy: 0.7334\n",
      "Epoch 89/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5401 - accuracy: 0.7331\n",
      "Epoch 90/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5400 - accuracy: 0.7338\n",
      "Epoch 91/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5400 - accuracy: 0.7335\n",
      "Epoch 92/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5399 - accuracy: 0.7335\n",
      "Epoch 93/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5399 - accuracy: 0.7339\n",
      "Epoch 94/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5398 - accuracy: 0.7339\n",
      "Epoch 95/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5398 - accuracy: 0.7339\n",
      "Epoch 96/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5398 - accuracy: 0.7343\n",
      "Epoch 97/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5397 - accuracy: 0.7342\n",
      "Epoch 98/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5397 - accuracy: 0.7339\n",
      "Epoch 99/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5396 - accuracy: 0.7339\n",
      "Epoch 100/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5396 - accuracy: 0.7338\n",
      "Epoch 101/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5395 - accuracy: 0.7339\n",
      "Epoch 102/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5395 - accuracy: 0.7339\n",
      "Epoch 103/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5394 - accuracy: 0.7344\n",
      "Epoch 104/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5394 - accuracy: 0.7343\n",
      "Epoch 105/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5393 - accuracy: 0.7346\n",
      "Epoch 106/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5393 - accuracy: 0.7344\n",
      "Epoch 107/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5392 - accuracy: 0.7348\n",
      "Epoch 108/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5392 - accuracy: 0.7348\n",
      "Epoch 109/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5391 - accuracy: 0.7344\n",
      "Epoch 110/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5391 - accuracy: 0.7342\n",
      "Epoch 111/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5391 - accuracy: 0.7346\n",
      "Epoch 112/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5390 - accuracy: 0.7346\n",
      "Epoch 113/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5390 - accuracy: 0.7342\n",
      "Epoch 114/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5389 - accuracy: 0.7343\n",
      "Epoch 115/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5389 - accuracy: 0.7346\n",
      "Epoch 116/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5388 - accuracy: 0.7346\n",
      "Epoch 117/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5388 - accuracy: 0.7344\n",
      "Epoch 118/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5387 - accuracy: 0.7340\n",
      "Epoch 119/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5387 - accuracy: 0.7342\n",
      "Epoch 120/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5386 - accuracy: 0.7342\n",
      "Epoch 121/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5386 - accuracy: 0.7340\n",
      "Epoch 122/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5385 - accuracy: 0.7344\n",
      "Epoch 123/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5385 - accuracy: 0.7342\n",
      "Epoch 124/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5384 - accuracy: 0.7344\n",
      "Epoch 125/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5384 - accuracy: 0.7344\n",
      "Epoch 126/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5383 - accuracy: 0.7342\n",
      "Epoch 127/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5383 - accuracy: 0.7343\n",
      "Epoch 128/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5382 - accuracy: 0.7340\n",
      "Epoch 129/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5382 - accuracy: 0.7340\n",
      "Epoch 130/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5381 - accuracy: 0.7339\n",
      "Epoch 131/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5381 - accuracy: 0.7343\n",
      "Epoch 132/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5380 - accuracy: 0.7347\n",
      "Epoch 133/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5380 - accuracy: 0.7351\n",
      "Epoch 134/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5380 - accuracy: 0.7348\n",
      "Epoch 135/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5379 - accuracy: 0.7350\n",
      "Epoch 136/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5379 - accuracy: 0.7348\n",
      "Epoch 137/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5378 - accuracy: 0.7355\n",
      "Epoch 138/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5378 - accuracy: 0.7354\n",
      "Epoch 139/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5377 - accuracy: 0.7351\n",
      "Epoch 140/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5377 - accuracy: 0.7351\n",
      "Epoch 141/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5376 - accuracy: 0.7351\n",
      "Epoch 142/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5376 - accuracy: 0.7346\n",
      "Epoch 143/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5375 - accuracy: 0.7347\n",
      "Epoch 144/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5375 - accuracy: 0.7346\n",
      "Epoch 145/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5374 - accuracy: 0.7350\n",
      "Epoch 146/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5374 - accuracy: 0.7348\n",
      "Epoch 147/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5373 - accuracy: 0.7351\n",
      "Epoch 148/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5373 - accuracy: 0.7354\n",
      "Epoch 149/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5373 - accuracy: 0.7351\n",
      "Epoch 150/500\n",
      "7403/7403 [==============================] - 0s 16us/step - loss: 0.5372 - accuracy: 0.7348\n",
      "Epoch 151/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5372 - accuracy: 0.7348\n",
      "Epoch 152/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5371 - accuracy: 0.7347\n",
      "Epoch 153/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5371 - accuracy: 0.7347\n",
      "Epoch 154/500\n",
      "7403/7403 [==============================] - 0s 16us/step - loss: 0.5371 - accuracy: 0.7348\n",
      "Epoch 155/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5370 - accuracy: 0.7348\n",
      "Epoch 156/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5370 - accuracy: 0.7348\n",
      "Epoch 157/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5370 - accuracy: 0.7351\n",
      "Epoch 158/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5369 - accuracy: 0.7348\n",
      "Epoch 159/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5369 - accuracy: 0.7346\n",
      "Epoch 160/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5369 - accuracy: 0.7348\n",
      "Epoch 161/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5369 - accuracy: 0.7347\n",
      "Epoch 162/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5368 - accuracy: 0.7347\n",
      "Epoch 163/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5368 - accuracy: 0.7347\n",
      "Epoch 164/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5368 - accuracy: 0.7350\n",
      "Epoch 165/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5367 - accuracy: 0.7347\n",
      "Epoch 166/500\n",
      "7403/7403 [==============================] - 0s 9us/step - loss: 0.5367 - accuracy: 0.7351\n",
      "Epoch 167/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5367 - accuracy: 0.7348\n",
      "Epoch 168/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5367 - accuracy: 0.7348\n",
      "Epoch 169/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5367 - accuracy: 0.7350\n",
      "Epoch 170/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5366 - accuracy: 0.7348\n",
      "Epoch 171/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5366 - accuracy: 0.7348\n",
      "Epoch 172/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5366 - accuracy: 0.7348\n",
      "Epoch 173/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5366 - accuracy: 0.7350\n",
      "Epoch 174/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5365 - accuracy: 0.7346\n",
      "Epoch 175/500\n",
      "7403/7403 [==============================] - 0s 16us/step - loss: 0.5365 - accuracy: 0.7344\n",
      "Epoch 176/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5365 - accuracy: 0.7344\n",
      "Epoch 177/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5365 - accuracy: 0.7347\n",
      "Epoch 178/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5365 - accuracy: 0.7346\n",
      "Epoch 179/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5364 - accuracy: 0.7348\n",
      "Epoch 180/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5364 - accuracy: 0.7350\n",
      "Epoch 181/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5364 - accuracy: 0.7350\n",
      "Epoch 182/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5364 - accuracy: 0.7350\n",
      "Epoch 183/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5364 - accuracy: 0.7351\n",
      "Epoch 184/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5363 - accuracy: 0.7351\n",
      "Epoch 185/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5363 - accuracy: 0.7350\n",
      "Epoch 186/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5363 - accuracy: 0.7350\n",
      "Epoch 187/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5363 - accuracy: 0.7348\n",
      "Epoch 188/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5363 - accuracy: 0.7346\n",
      "Epoch 189/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5363 - accuracy: 0.7347\n",
      "Epoch 190/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5362 - accuracy: 0.7344\n",
      "Epoch 191/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5362 - accuracy: 0.7343\n",
      "Epoch 192/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5362 - accuracy: 0.7346\n",
      "Epoch 193/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5362 - accuracy: 0.7346\n",
      "Epoch 194/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5362 - accuracy: 0.7342\n",
      "Epoch 195/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5362 - accuracy: 0.7342\n",
      "Epoch 196/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5362 - accuracy: 0.7342\n",
      "Epoch 197/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5361 - accuracy: 0.7342\n",
      "Epoch 198/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5361 - accuracy: 0.7340\n",
      "Epoch 199/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5361 - accuracy: 0.7343\n",
      "Epoch 200/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5361 - accuracy: 0.7340\n",
      "Epoch 201/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5361 - accuracy: 0.7343\n",
      "Epoch 202/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5361 - accuracy: 0.7342\n",
      "Epoch 203/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5361 - accuracy: 0.7342\n",
      "Epoch 204/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5360 - accuracy: 0.7344\n",
      "Epoch 205/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5360 - accuracy: 0.7346\n",
      "Epoch 206/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5360 - accuracy: 0.7346\n",
      "Epoch 207/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5360 - accuracy: 0.7346\n",
      "Epoch 208/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5360 - accuracy: 0.7344\n",
      "Epoch 209/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5360 - accuracy: 0.7344\n",
      "Epoch 210/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5360 - accuracy: 0.7346\n",
      "Epoch 211/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5359 - accuracy: 0.7346\n",
      "Epoch 212/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5359 - accuracy: 0.7343\n",
      "Epoch 213/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5359 - accuracy: 0.7343\n",
      "Epoch 214/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5359 - accuracy: 0.7340\n",
      "Epoch 215/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5359 - accuracy: 0.7340\n",
      "Epoch 216/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5359 - accuracy: 0.7347\n",
      "Epoch 217/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5359 - accuracy: 0.7342\n",
      "Epoch 218/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5359 - accuracy: 0.7347\n",
      "Epoch 219/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5359 - accuracy: 0.7340\n",
      "Epoch 220/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5359 - accuracy: 0.7351\n",
      "Epoch 221/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5358 - accuracy: 0.7355\n",
      "Epoch 222/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5358 - accuracy: 0.7354\n",
      "Epoch 223/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5358 - accuracy: 0.7352\n",
      "Epoch 224/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5358 - accuracy: 0.7354\n",
      "Epoch 225/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5358 - accuracy: 0.7352\n",
      "Epoch 226/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5358 - accuracy: 0.7352\n",
      "Epoch 227/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7350\n",
      "Epoch 228/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7350\n",
      "Epoch 229/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7348\n",
      "Epoch 230/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5357 - accuracy: 0.7347\n",
      "Epoch 231/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5357 - accuracy: 0.7344\n",
      "Epoch 232/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7350\n",
      "Epoch 233/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5357 - accuracy: 0.7344\n",
      "Epoch 234/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5356 - accuracy: 0.7346\n",
      "Epoch 235/500\n",
      "7403/7403 [==============================] - 0s 9us/step - loss: 0.5356 - accuracy: 0.7344\n",
      "Epoch 236/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5356 - accuracy: 0.7343\n",
      "Epoch 237/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5356 - accuracy: 0.7347\n",
      "Epoch 238/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5356 - accuracy: 0.7347\n",
      "Epoch 239/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5356 - accuracy: 0.7350\n",
      "Epoch 240/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5356 - accuracy: 0.7348\n",
      "Epoch 241/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5356 - accuracy: 0.7352\n",
      "Epoch 242/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5355 - accuracy: 0.7351\n",
      "Epoch 243/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5355 - accuracy: 0.7352\n",
      "Epoch 244/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5355 - accuracy: 0.7351\n",
      "Epoch 245/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5355 - accuracy: 0.7351\n",
      "Epoch 246/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5355 - accuracy: 0.7352\n",
      "Epoch 247/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5355 - accuracy: 0.7351\n",
      "Epoch 248/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5355 - accuracy: 0.7351\n",
      "Epoch 249/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5355 - accuracy: 0.7351\n",
      "Epoch 250/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5354 - accuracy: 0.7350\n",
      "Epoch 251/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5354 - accuracy: 0.7348\n",
      "Epoch 252/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5354 - accuracy: 0.7346\n",
      "Epoch 253/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5354 - accuracy: 0.7347\n",
      "Epoch 254/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5353 - accuracy: 0.7346\n",
      "Epoch 255/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5353 - accuracy: 0.7346\n",
      "Epoch 256/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5353 - accuracy: 0.7346\n",
      "Epoch 257/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5353 - accuracy: 0.7346\n",
      "Epoch 258/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5353 - accuracy: 0.7346\n",
      "Epoch 259/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5353 - accuracy: 0.7344\n",
      "Epoch 260/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5352 - accuracy: 0.7347\n",
      "Epoch 261/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5352 - accuracy: 0.7347\n",
      "Epoch 262/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5352 - accuracy: 0.7348\n",
      "Epoch 263/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5352 - accuracy: 0.7348\n",
      "Epoch 264/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5351 - accuracy: 0.7348\n",
      "Epoch 265/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5351 - accuracy: 0.7350\n",
      "Epoch 266/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5351 - accuracy: 0.7354\n",
      "Epoch 267/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5350 - accuracy: 0.7354\n",
      "Epoch 268/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5349 - accuracy: 0.7352\n",
      "Epoch 269/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5349 - accuracy: 0.7352\n",
      "Epoch 270/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5348 - accuracy: 0.7356\n",
      "Epoch 271/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5348 - accuracy: 0.7356\n",
      "Epoch 272/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5347 - accuracy: 0.7355\n",
      "Epoch 273/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5347 - accuracy: 0.7351\n",
      "Epoch 274/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5346 - accuracy: 0.7351\n",
      "Epoch 275/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5346 - accuracy: 0.7352\n",
      "Epoch 276/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5345 - accuracy: 0.7346\n",
      "Epoch 277/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5344 - accuracy: 0.7352\n",
      "Epoch 278/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5344 - accuracy: 0.7352\n",
      "Epoch 279/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5343 - accuracy: 0.7352\n",
      "Epoch 280/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5342 - accuracy: 0.7350\n",
      "Epoch 281/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5341 - accuracy: 0.7358\n",
      "Epoch 282/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5340 - accuracy: 0.7354\n",
      "Epoch 283/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5339 - accuracy: 0.7358\n",
      "Epoch 284/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5338 - accuracy: 0.7352\n",
      "Epoch 285/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5337 - accuracy: 0.7356\n",
      "Epoch 286/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5336 - accuracy: 0.7359\n",
      "Epoch 287/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5335 - accuracy: 0.7361\n",
      "Epoch 288/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5335 - accuracy: 0.7356\n",
      "Epoch 289/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5334 - accuracy: 0.7355\n",
      "Epoch 290/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5334 - accuracy: 0.7359\n",
      "Epoch 291/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5333 - accuracy: 0.7361\n",
      "Epoch 292/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5332 - accuracy: 0.7356\n",
      "Epoch 293/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5332 - accuracy: 0.7356\n",
      "Epoch 294/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5332 - accuracy: 0.7358\n",
      "Epoch 295/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5331 - accuracy: 0.7362\n",
      "Epoch 296/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5331 - accuracy: 0.7359\n",
      "Epoch 297/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5330 - accuracy: 0.7355\n",
      "Epoch 298/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5330 - accuracy: 0.7355\n",
      "Epoch 299/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5330 - accuracy: 0.7361\n",
      "Epoch 300/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5329 - accuracy: 0.7361\n",
      "Epoch 301/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5329 - accuracy: 0.7363\n",
      "Epoch 302/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5328 - accuracy: 0.7363\n",
      "Epoch 303/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5328 - accuracy: 0.7365\n",
      "Epoch 304/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5327 - accuracy: 0.7365\n",
      "Epoch 305/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5327 - accuracy: 0.7365\n",
      "Epoch 306/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5327 - accuracy: 0.7369\n",
      "Epoch 307/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5326 - accuracy: 0.7367\n",
      "Epoch 308/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5326 - accuracy: 0.7367\n",
      "Epoch 309/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5325 - accuracy: 0.7369\n",
      "Epoch 310/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5325 - accuracy: 0.7367\n",
      "Epoch 311/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5325 - accuracy: 0.7367\n",
      "Epoch 312/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5324 - accuracy: 0.7369\n",
      "Epoch 313/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5324 - accuracy: 0.7369\n",
      "Epoch 314/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5324 - accuracy: 0.7369\n",
      "Epoch 315/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5323 - accuracy: 0.7367\n",
      "Epoch 316/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5323 - accuracy: 0.7362\n",
      "Epoch 317/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5323 - accuracy: 0.7363\n",
      "Epoch 318/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5322 - accuracy: 0.7362\n",
      "Epoch 319/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5322 - accuracy: 0.7365\n",
      "Epoch 320/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5322 - accuracy: 0.7362\n",
      "Epoch 321/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5321 - accuracy: 0.7365\n",
      "Epoch 322/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5321 - accuracy: 0.7366\n",
      "Epoch 323/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5321 - accuracy: 0.7366\n",
      "Epoch 324/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5320 - accuracy: 0.7363\n",
      "Epoch 325/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5320 - accuracy: 0.7365\n",
      "Epoch 326/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5320 - accuracy: 0.7369\n",
      "Epoch 327/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5320 - accuracy: 0.7365\n",
      "Epoch 328/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5319 - accuracy: 0.7366\n",
      "Epoch 329/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5319 - accuracy: 0.7363\n",
      "Epoch 330/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5319 - accuracy: 0.7365\n",
      "Epoch 331/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5319 - accuracy: 0.7363\n",
      "Epoch 332/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5319 - accuracy: 0.7366\n",
      "Epoch 333/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5318 - accuracy: 0.7363\n",
      "Epoch 334/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5318 - accuracy: 0.7366\n",
      "Epoch 335/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5318 - accuracy: 0.7367\n",
      "Epoch 336/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5318 - accuracy: 0.7366\n",
      "Epoch 337/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5318 - accuracy: 0.7363\n",
      "Epoch 338/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5317 - accuracy: 0.7363\n",
      "Epoch 339/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5317 - accuracy: 0.7363\n",
      "Epoch 340/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5317 - accuracy: 0.7363\n",
      "Epoch 341/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5317 - accuracy: 0.7363\n",
      "Epoch 342/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5316 - accuracy: 0.7363\n",
      "Epoch 343/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5316 - accuracy: 0.7363\n",
      "Epoch 344/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5316 - accuracy: 0.7365\n",
      "Epoch 345/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5316 - accuracy: 0.7366\n",
      "Epoch 346/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5316 - accuracy: 0.7366\n",
      "Epoch 347/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5316 - accuracy: 0.7366\n",
      "Epoch 348/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5316 - accuracy: 0.7365\n",
      "Epoch 349/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5315 - accuracy: 0.7365\n",
      "Epoch 350/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5315 - accuracy: 0.7367\n",
      "Epoch 351/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5315 - accuracy: 0.7366\n",
      "Epoch 352/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5315 - accuracy: 0.7363\n",
      "Epoch 353/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5315 - accuracy: 0.7366\n",
      "Epoch 354/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5314 - accuracy: 0.7370\n",
      "Epoch 355/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5314 - accuracy: 0.7366\n",
      "Epoch 356/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5314 - accuracy: 0.7370\n",
      "Epoch 357/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5314 - accuracy: 0.7369\n",
      "Epoch 358/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5314 - accuracy: 0.7369\n",
      "Epoch 359/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5314 - accuracy: 0.7363\n",
      "Epoch 360/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5314 - accuracy: 0.7363\n",
      "Epoch 361/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5313 - accuracy: 0.7363\n",
      "Epoch 362/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5313 - accuracy: 0.7361\n",
      "Epoch 363/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5313 - accuracy: 0.7365\n",
      "Epoch 364/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5313 - accuracy: 0.7363\n",
      "Epoch 365/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5313 - accuracy: 0.7363\n",
      "Epoch 366/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5313 - accuracy: 0.7366\n",
      "Epoch 367/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5313 - accuracy: 0.7361\n",
      "Epoch 368/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5312 - accuracy: 0.7362\n",
      "Epoch 369/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5312 - accuracy: 0.7362\n",
      "Epoch 370/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5312 - accuracy: 0.7362\n",
      "Epoch 371/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5312 - accuracy: 0.7361\n",
      "Epoch 372/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5312 - accuracy: 0.7361\n",
      "Epoch 373/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5312 - accuracy: 0.7359\n",
      "Epoch 374/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5311 - accuracy: 0.7359\n",
      "Epoch 375/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5311 - accuracy: 0.7354\n",
      "Epoch 376/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5311 - accuracy: 0.7354\n",
      "Epoch 377/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5311 - accuracy: 0.7352\n",
      "Epoch 378/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5311 - accuracy: 0.7354\n",
      "Epoch 379/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5311 - accuracy: 0.7355\n",
      "Epoch 380/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5311 - accuracy: 0.7354\n",
      "Epoch 381/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5311 - accuracy: 0.7355\n",
      "Epoch 382/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5311 - accuracy: 0.7354\n",
      "Epoch 383/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5310 - accuracy: 0.7356\n",
      "Epoch 384/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5310 - accuracy: 0.7356\n",
      "Epoch 385/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5310 - accuracy: 0.7356\n",
      "Epoch 386/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5310 - accuracy: 0.7359\n",
      "Epoch 387/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5310 - accuracy: 0.7359\n",
      "Epoch 388/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5310 - accuracy: 0.7361\n",
      "Epoch 389/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5310 - accuracy: 0.7361\n",
      "Epoch 390/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5310 - accuracy: 0.7363\n",
      "Epoch 391/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5310 - accuracy: 0.7362\n",
      "Epoch 392/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5310 - accuracy: 0.7363\n",
      "Epoch 393/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5309 - accuracy: 0.7365\n",
      "Epoch 394/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5309 - accuracy: 0.7363\n",
      "Epoch 395/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5309 - accuracy: 0.7362\n",
      "Epoch 396/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5309 - accuracy: 0.7361\n",
      "Epoch 397/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5309 - accuracy: 0.7359\n",
      "Epoch 398/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5309 - accuracy: 0.7362\n",
      "Epoch 399/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5309 - accuracy: 0.7359\n",
      "Epoch 400/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5309 - accuracy: 0.7362\n",
      "Epoch 401/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5309 - accuracy: 0.7359\n",
      "Epoch 402/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5308 - accuracy: 0.7359\n",
      "Epoch 403/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5308 - accuracy: 0.7356\n",
      "Epoch 404/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5308 - accuracy: 0.7356\n",
      "Epoch 405/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5308 - accuracy: 0.7361\n",
      "Epoch 406/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5308 - accuracy: 0.7355\n",
      "Epoch 407/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5308 - accuracy: 0.7358\n",
      "Epoch 408/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5308 - accuracy: 0.7358\n",
      "Epoch 409/500\n",
      "7403/7403 [==============================] - 0s 17us/step - loss: 0.5308 - accuracy: 0.7356\n",
      "Epoch 410/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5308 - accuracy: 0.7358\n",
      "Epoch 411/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5308 - accuracy: 0.7356\n",
      "Epoch 412/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5307 - accuracy: 0.7356\n",
      "Epoch 413/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5307 - accuracy: 0.7356\n",
      "Epoch 414/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5307 - accuracy: 0.7356\n",
      "Epoch 415/500\n",
      "7403/7403 [==============================] - 0s 15us/step - loss: 0.5307 - accuracy: 0.7354\n",
      "Epoch 416/500\n",
      "7403/7403 [==============================] - 0s 18us/step - loss: 0.5307 - accuracy: 0.7354\n",
      "Epoch 417/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5307 - accuracy: 0.7356\n",
      "Epoch 418/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5307 - accuracy: 0.7356\n",
      "Epoch 419/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5307 - accuracy: 0.7354\n",
      "Epoch 420/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5307 - accuracy: 0.7358\n",
      "Epoch 421/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5307 - accuracy: 0.7359\n",
      "Epoch 422/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5306 - accuracy: 0.7356\n",
      "Epoch 423/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5306 - accuracy: 0.7356\n",
      "Epoch 424/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5306 - accuracy: 0.7358\n",
      "Epoch 425/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5306 - accuracy: 0.7355\n",
      "Epoch 426/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5306 - accuracy: 0.7356\n",
      "Epoch 427/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5306 - accuracy: 0.7356\n",
      "Epoch 428/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5306 - accuracy: 0.7358\n",
      "Epoch 429/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5306 - accuracy: 0.7359\n",
      "Epoch 430/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5305 - accuracy: 0.7359\n",
      "Epoch 431/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5305 - accuracy: 0.7355\n",
      "Epoch 432/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5305 - accuracy: 0.7361\n",
      "Epoch 433/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5305 - accuracy: 0.7365\n",
      "Epoch 434/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5305 - accuracy: 0.7361\n",
      "Epoch 435/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5305 - accuracy: 0.7361\n",
      "Epoch 436/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5305 - accuracy: 0.7361\n",
      "Epoch 437/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5305 - accuracy: 0.7358\n",
      "Epoch 438/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5305 - accuracy: 0.7361\n",
      "Epoch 439/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5304 - accuracy: 0.7359\n",
      "Epoch 440/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5304 - accuracy: 0.7362\n",
      "Epoch 441/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5304 - accuracy: 0.7362\n",
      "Epoch 442/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5304 - accuracy: 0.7361\n",
      "Epoch 443/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5304 - accuracy: 0.7361\n",
      "Epoch 444/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5304 - accuracy: 0.7363\n",
      "Epoch 445/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5304 - accuracy: 0.7363\n",
      "Epoch 446/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5303 - accuracy: 0.7363\n",
      "Epoch 447/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5303 - accuracy: 0.7362\n",
      "Epoch 448/500\n",
      "7403/7403 [==============================] - 0s 15us/step - loss: 0.5303 - accuracy: 0.7365\n",
      "Epoch 449/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5303 - accuracy: 0.7361\n",
      "Epoch 450/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5303 - accuracy: 0.7359\n",
      "Epoch 451/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5303 - accuracy: 0.7359\n",
      "Epoch 452/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5303 - accuracy: 0.7365\n",
      "Epoch 453/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5303 - accuracy: 0.7361\n",
      "Epoch 454/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5302 - accuracy: 0.7362\n",
      "Epoch 455/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5302 - accuracy: 0.7366\n",
      "Epoch 456/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5302 - accuracy: 0.7366\n",
      "Epoch 457/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5302 - accuracy: 0.7367\n",
      "Epoch 458/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5302 - accuracy: 0.7366\n",
      "Epoch 459/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5302 - accuracy: 0.7366\n",
      "Epoch 460/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5302 - accuracy: 0.7365\n",
      "Epoch 461/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5302 - accuracy: 0.7365\n",
      "Epoch 462/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5301 - accuracy: 0.7366\n",
      "Epoch 463/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5301 - accuracy: 0.7369\n",
      "Epoch 464/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5301 - accuracy: 0.7365\n",
      "Epoch 465/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5301 - accuracy: 0.7369\n",
      "Epoch 466/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5301 - accuracy: 0.7363\n",
      "Epoch 467/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5301 - accuracy: 0.7363\n",
      "Epoch 468/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5301 - accuracy: 0.7363\n",
      "Epoch 469/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5300 - accuracy: 0.7362\n",
      "Epoch 470/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5300 - accuracy: 0.7363\n",
      "Epoch 471/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5300 - accuracy: 0.7363\n",
      "Epoch 472/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5300 - accuracy: 0.7362\n",
      "Epoch 473/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5300 - accuracy: 0.7366\n",
      "Epoch 474/500\n",
      "7403/7403 [==============================] - 0s 10us/step - loss: 0.5300 - accuracy: 0.7365\n",
      "Epoch 475/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5300 - accuracy: 0.7369\n",
      "Epoch 476/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5300 - accuracy: 0.7369\n",
      "Epoch 477/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5300 - accuracy: 0.7373\n",
      "Epoch 478/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5300 - accuracy: 0.7373\n",
      "Epoch 479/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5299 - accuracy: 0.7374\n",
      "Epoch 480/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5299 - accuracy: 0.7370\n",
      "Epoch 481/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5299 - accuracy: 0.7369\n",
      "Epoch 482/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5299 - accuracy: 0.7370\n",
      "Epoch 483/500\n",
      "7403/7403 [==============================] - 0s 17us/step - loss: 0.5299 - accuracy: 0.7369\n",
      "Epoch 484/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5299 - accuracy: 0.7369\n",
      "Epoch 485/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5299 - accuracy: 0.7366\n",
      "Epoch 486/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5299 - accuracy: 0.7367\n",
      "Epoch 487/500\n",
      "7403/7403 [==============================] - 0s 17us/step - loss: 0.5299 - accuracy: 0.7370\n",
      "Epoch 488/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5299 - accuracy: 0.7367\n",
      "Epoch 489/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5299 - accuracy: 0.7369\n",
      "Epoch 490/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5298 - accuracy: 0.7369\n",
      "Epoch 491/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5298 - accuracy: 0.7367\n",
      "Epoch 492/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5298 - accuracy: 0.7366\n",
      "Epoch 493/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5298 - accuracy: 0.7369\n",
      "Epoch 494/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5298 - accuracy: 0.7369\n",
      "Epoch 495/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5298 - accuracy: 0.7370\n",
      "Epoch 496/500\n",
      "7403/7403 [==============================] - 0s 13us/step - loss: 0.5298 - accuracy: 0.7370\n",
      "Epoch 497/500\n",
      "7403/7403 [==============================] - 0s 12us/step - loss: 0.5297 - accuracy: 0.7370\n",
      "Epoch 498/500\n",
      "7403/7403 [==============================] - 0s 11us/step - loss: 0.5297 - accuracy: 0.7369\n",
      "Epoch 499/500\n",
      "7403/7403 [==============================] - 0s 14us/step - loss: 0.5297 - accuracy: 0.7370\n",
      "Epoch 500/500\n",
      "7403/7403 [==============================] - 0s 17us/step - loss: 0.5297 - accuracy: 0.7370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8fb197f150>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(xn_train, y_train_b, batch_size=128, epochs=500, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-xaaVX0Rwqx",
    "outputId": "0c159a58-493e-4100-93a4-bd07c56e7c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7200161814689636\n"
     ]
    }
   ],
   "source": [
    "score = nn.evaluate(xn_test, y_test_b, verbose=0) #Compute test set accuracy\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "lMqzZRrNRwqx"
   },
   "outputs": [],
   "source": [
    "p_test = nn.predict_classes(xn_test) # Use trained neural network to predict test points\n",
    "p_test = p_test.reshape((p_test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "B-IYvFk7Rwqy"
   },
   "outputs": [],
   "source": [
    "# Store (normalized) instances that were predicted as Bad\n",
    "z_test = np.hstack((xn_test, p_test)) \n",
    "z_test_bad = z_test[z_test[:,-1]==0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vI5m3WyoRwqz",
    "outputId": "a1249dc5-911a-4fce-a95e-c93df56e0858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21276596 -0.35554172 -0.48694517 -0.40501319 -0.32278481 -0.5\n",
      " -0.5         0.36       -0.42771084 -0.05555556  0.16666667 -0.36538462\n",
      " -0.44736842  0.07       -0.5        -0.5        -0.5        -0.20258621\n",
      " -0.2940552  -0.46875    -0.41304348 -0.44444444 -0.07        0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(z_test_bad[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "2sjthNgLRwqz"
   },
   "outputs": [],
   "source": [
    "# Store (unnormalized) instances that were predicted as Bad\n",
    "zun_test = np.hstack((x_test, p_test)) \n",
    "zun_test_bad = zun_test[zun_test[:,-1]==0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05vhKhmbRwqz",
    "outputId": "e38471ea-3f5c-491d-e73a-893771dc6372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 67 116   5  40  14   0   0  86   6   4   6  14   1  57   0   0   0  69\n",
      "  97   1   2   1  43   0]\n"
     ]
    }
   ],
   "source": [
    "print(zun_test_bad[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "j77Brzt4Rwqz"
   },
   "outputs": [],
   "source": [
    "idx = 8\n",
    "\n",
    "X = xn_test[idx].reshape((1,) + xn_test[8].shape)\n",
    "\n",
    "# attach the prediction made by the model to X\n",
    "X = np.hstack((X, nn.predict_classes(X).reshape((1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "5_upm6fTRwqz"
   },
   "outputs": [],
   "source": [
    "explainer = ProtodashExplainer()\n",
    "(W, S, setValues) = explainer.explain(X, z_test_bad, m=5) # Return weights W, Prototypes S and objective function values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1021yZ9Z03X"
   },
   "source": [
    "Task 5: Modify the input parameters for the ProtodashExplainer such that comparisons against 10 closest cases classified as good are being performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDij9rSJmgng"
   },
   "source": [
    "**TASK 5 SOLUTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bB8sRTzlsR-8"
   },
   "source": [
    "First we score normalized instances that was predicted as good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "6K5RbK2smmwl"
   },
   "outputs": [],
   "source": [
    "z_test = np.hstack((xn_test, p_test)) \n",
    "z_test_good = z_test[z_test[:,-1]==0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZ34MqrFsmA9",
    "outputId": "aacd1ef2-92fb-4224-9ed2-05472ec734c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12765957 -0.46513076 -0.49477807 -0.4762533  -0.42405063 -0.5\n",
      " -0.5         0.5        -0.5         0.27777778  0.5        -0.43269231\n",
      " -0.28947368 -0.07       -0.5        -0.5        -0.5        -0.07758621\n",
      " -0.33651805 -0.40625    -0.36956522 -0.33333333  0.5         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(z_test_good[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "uS0UEqGRsmEW"
   },
   "outputs": [],
   "source": [
    "idy = 10\n",
    "\n",
    "Y = xn_test[idx].reshape((1,) + xn_test[10].shape)\n",
    "\n",
    "# attach the prediction made by the model to X\n",
    "Y = np.hstack((Y, nn.predict_classes(Y).reshape((1,1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EPZWa4ruUQA"
   },
   "source": [
    "Now, modifying the input parameters for the ProtodashEXPLORER such that comparisons against 10 closest cases classified as good are being performed, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "3po399s8ukBd"
   },
   "outputs": [],
   "source": [
    "explainer = ProtodashExplainer()\n",
    "(W, S, setValues) = explainer.explain(Y, z_test_good, m=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drel4O6RutVh",
    "outputId": "e0a28bd3-8816-4c9d-b457-832da4246c79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<aix360.algorithms.protodash.PDASH.ProtodashExplainer at 0x7f8fa1ddcf50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "yKXRiljdRwq0",
    "outputId": "72ccde6b-da78-4c14-9ef6-20d46b11132f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d1b54019-26b2-4a3b-80ce-8052f5012dd7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExternalRiskEstimate</th>\n",
       "      <td>81.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceOldestTradeOpen</th>\n",
       "      <td>300.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceMostRecentTradeOpen</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AverageMInFile</th>\n",
       "      <td>90.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumSatisfactoryTrades</th>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTrades60Ever2DerogPubRec</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTrades90Ever2DerogPubRec</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentTradesNeverDelq</th>\n",
       "      <td>100.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceMostRecentDelq</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDelq2PublicRecLast12M</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDelqEver</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTotalTrades</th>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTradesOpeninLast12M</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentInstallTrades</th>\n",
       "      <td>21.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceMostRecentInqexcl7days</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInqLast6M</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInqLast6Mexcl7days</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetFractionRevolvingBurden</th>\n",
       "      <td>17.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetFractionInstallBurden</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumRevolvingTradesWBalance</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInstallTradesWBalance</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentTradesWBalance</th>\n",
       "      <td>31.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RiskPerformance</th>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Good</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.229172</td>\n",
       "      <td>0.012965</td>\n",
       "      <td>0.056328</td>\n",
       "      <td>0.082895</td>\n",
       "      <td>0.060682</td>\n",
       "      <td>0.280235</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>0.221207</td>\n",
       "      <td>0.047638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1b54019-26b2-4a3b-80ce-8052f5012dd7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d1b54019-26b2-4a3b-80ce-8052f5012dd7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d1b54019-26b2-4a3b-80ce-8052f5012dd7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                           0         1         2         3         4         5         6         7         8         9\n",
       "ExternalRiskEstimate                    81.0      52.0      82.0      82.0      77.0      76.0      87.0      66.0      86.0      68.0\n",
       "MSinceOldestTradeOpen                  300.0     197.0     191.0     111.0     154.0      94.0       0.0     204.0     264.0     178.0\n",
       "MSinceMostRecentTradeOpen                2.0       5.0      12.0      18.0       3.0       2.0      32.0       6.0       5.0       7.0\n",
       "AverageMInFile                          90.0      78.0      98.0      67.0      55.0      49.0      97.0      89.0     134.0      74.0\n",
       "NumSatisfactoryTrades                   18.0      17.0       9.0       4.0      31.0      25.0      16.0      20.0      17.0      30.0\n",
       "NumTrades60Ever2DerogPubRec              0.0       4.0       1.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
       "NumTrades90Ever2DerogPubRec              0.0       1.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
       "PercentTradesNeverDelq                 100.0      71.0      90.0     100.0     100.0     100.0     100.0     100.0     100.0      97.0\n",
       "MSinceMostRecentDelq                     0.0       3.0      35.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0\n",
       "MaxDelq2PublicRecLast12M                 7.0       4.0       6.0       7.0       7.0       7.0       7.0       7.0       7.0       6.0\n",
       "MaxDelqEver                              8.0       5.0       5.0       8.0       8.0       8.0       8.0       8.0       8.0       6.0\n",
       "NumTotalTrades                          19.0      22.0      10.0       4.0      32.0      30.0       0.0      20.0      17.0      30.0\n",
       "NumTradesOpeninLast12M                   4.0       1.0       0.0       0.0       6.0       5.0       0.0       1.0       2.0       1.0\n",
       "PercentInstallTrades                    21.0      38.0      60.0      50.0      63.0      33.0      41.0      40.0      12.0      23.0\n",
       "MSinceMostRecentInqexcl7days             2.0       0.0       3.0       0.0       2.0       0.0       0.0       0.0       0.0       0.0\n",
       "NumInqLast6M                             1.0       0.0       1.0       0.0       2.0       4.0       0.0       1.0       0.0       1.0\n",
       "NumInqLast6Mexcl7days                    1.0       0.0       1.0       0.0       1.0       4.0       0.0       1.0       0.0       1.0\n",
       "NetFractionRevolvingBurden              17.0      96.0       0.0      14.0      26.0      20.0       9.0      90.0      13.0      45.0\n",
       "NetFractionInstallBurden                 0.0      31.0      78.0       0.0      74.0      81.0      79.0     100.0      95.0      88.0\n",
       "NumRevolvingTradesWBalance               3.0       6.0       0.0       1.0       5.0       2.0       3.0       2.0       6.0       4.0\n",
       "NumInstallTradesWBalance                 1.0       2.0       2.0       0.0      14.0       4.0       2.0       2.0       2.0       2.0\n",
       "NumBank2NatlTradesWHighUtilization       1.0       3.0       0.0       0.0       0.0       0.0       0.0       1.0       0.0       3.0\n",
       "PercentTradesWBalance                   31.0      89.0      60.0     100.0      86.0      40.0      83.0     100.0      67.0      50.0\n",
       "RiskPerformance                         Good       Bad      Good      Good      Good      Good      Good       Bad      Good       Bad\n",
       "Weight                              0.000062  0.229172  0.012965  0.056328  0.082895  0.060682  0.280235  0.008814  0.221207  0.047638"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.DataFrame.from_records(zun_test[S, 0:-1].astype('double'))\n",
    "RP=[]\n",
    "for i in range(S.shape[0]):\n",
    "    RP.append(class_names[int(z_test[S[i], -1])]) # Append class names\n",
    "dfs[23] = RP\n",
    "dfs.columns = df.columns  \n",
    "dfs[\"Weight\"] = np.around(W, 5)/np.sum(np.around(W, 5)) # Calculate normalized importance weights\n",
    "dfs.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 771
    },
    "id": "AwvBkJ6oRwq0",
    "outputId": "4ff8c2c5-2dce-430c-f0fa-4d436bdf6ad9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-dd1eceba-9289-425e-a341-d9e0fcfb720f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExternalRiskEstimate</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceOldestTradeOpen</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceMostRecentTradeOpen</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AverageMInFile</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumSatisfactoryTrades</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTrades60Ever2DerogPubRec</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTrades90Ever2DerogPubRec</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentTradesNeverDelq</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceMostRecentDelq</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDelq2PublicRecLast12M</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDelqEver</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTotalTrades</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTradesOpeninLast12M</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentInstallTrades</th>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceMostRecentInqexcl7days</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInqLast6M</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInqLast6Mexcl7days</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetFractionRevolvingBurden</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetFractionInstallBurden</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumRevolvingTradesWBalance</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInstallTradesWBalance</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentTradesWBalance</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd1eceba-9289-425e-a341-d9e0fcfb720f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-dd1eceba-9289-425e-a341-d9e0fcfb720f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-dd1eceba-9289-425e-a341-d9e0fcfb720f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                       0     1     2     3     4     5     6     7     8     9\n",
       "ExternalRiskEstimate                0.20  0.11  0.24  0.15  0.07  0.06  1.00  0.04  0.31  0.65\n",
       "MSinceOldestTradeOpen               0.91  0.30  0.25  0.40  0.75  0.70  0.62  0.49  0.16  0.31\n",
       "MSinceMostRecentTradeOpen           0.89  0.83  0.24  0.86  0.88  0.84  0.88  0.06  0.84  0.16\n",
       "AverageMInFile                      0.90  0.57  0.85  0.96  0.86  0.96  0.76  0.05  0.20  0.52\n",
       "NumSatisfactoryTrades               0.94  0.67  0.30  0.80  0.09  0.64  0.94  0.34  0.60  0.30\n",
       "NumTrades60Ever2DerogPubRec         1.00  1.00  0.62  0.23  1.00  0.03  0.62  0.38  0.62  1.00\n",
       "NumTrades90Ever2DerogPubRec         1.00  1.00  1.00  0.62  1.00  0.03  1.00  0.62  1.00  1.00\n",
       "PercentTradesNeverDelq              0.85  0.91  0.05  0.46  0.74  0.74  0.47  0.26  0.94  0.74\n",
       "MSinceMostRecentDelq                0.60  0.10  0.74  0.37  0.33  0.33  0.55  0.34  0.96  0.33\n",
       "MaxDelq2PublicRecLast12M            1.00  1.00  1.00  0.37  0.61  0.05  1.00  0.37  1.00  0.61\n",
       "MaxDelqEver                         1.00  1.00  0.49  0.24  0.24  0.24  0.49  0.49  0.49  0.24\n",
       "NumTotalTrades                      1.00  0.60  0.34  0.54  0.09  0.95  0.90  0.38  0.63  0.33\n",
       "NumTradesOpeninLast12M              1.00  0.11  1.00  0.57  0.06  0.32  1.00  1.00  1.00  1.00\n",
       "PercentInstallTrades                0.87  1.00  0.73  0.97  0.23  0.73  0.78  0.57  0.73  0.04\n",
       "MSinceMostRecentInqexcl7days        1.00  1.00  1.00  0.04  1.00  1.00  1.00  1.00  1.00  1.00\n",
       "NumInqLast6M                        0.50  0.06  1.00  1.00  0.09  0.71  1.00  0.71  1.00  1.00\n",
       "NumInqLast6Mexcl7days               0.50  0.06  1.00  1.00  0.09  0.71  1.00  0.71  1.00  1.00\n",
       "NetFractionRevolvingBurden          0.18  0.32  0.90  0.87  0.06  0.96  0.90  0.96  0.18  0.90\n",
       "NetFractionInstallBurden            1.00  0.15  1.00  1.00  0.18  0.06  1.00  1.00  1.00  1.00\n",
       "NumRevolvingTradesWBalance          0.87  0.44  0.58  0.87  0.06  0.87  0.58  0.66  0.87  0.58\n",
       "NumInstallTradesWBalance            1.00  1.00  0.84  0.84  0.04  1.00  1.00  0.84  0.84  1.00\n",
       "NumBank2NatlTradesWHighUtilization  1.00  0.80  0.80  0.80  0.04  0.80  0.80  0.80  1.00  0.80\n",
       "PercentTradesWBalance               0.94  0.88  0.16  0.62  0.23  0.83  0.50  0.16  0.75  0.16"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = z_test_bad[S, 0:-1] # Store the prototypes\n",
    "eps = 1e-10 # Small constant to guard against divide by zero errors\n",
    "fwt = np.zeros(z.shape)\n",
    "for i in range (z.shape[0]): # Compute feature similarity for each prototype\n",
    "    for j in range(z.shape[1]):\n",
    "        fwt[i, j] = np.exp(-1 * abs(X[0, j] - z[i,j])/(np.std(z[:, j])+eps))\n",
    "                \n",
    "# move wts to a dataframe to display\n",
    "dfw = pd.DataFrame.from_records(np.around(fwt.astype('double'), 2))\n",
    "dfw.columns = df.columns[:-1]\n",
    "dfw.transpose()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7hExopzpRwq1",
    "outputId": "25024f28-d80a-4dd9-8098-5a7ce337aab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PN for Sample: 20\n",
      "Prediction made by the model: [[-0.27486533  0.39342535]]\n",
      "Prediction probabilities: Good\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:60: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:151: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:213: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:216: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/aix360/algorithms/contrastive/CEM_aen.py:230: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "iter:0 const:[10.]\n",
      "Loss_Overall:0.2212, Loss_Attack:0.0000\n",
      "Loss_L2Dist:0.1327, Loss_L1Dist:0.8852, AE_loss:0.0\n",
      "target_lab_score:-0.7366, max_nontarget_lab_score:0.8075\n",
      "\n",
      "iter:500 const:[10.]\n",
      "Loss_Overall:2.0237, Loss_Attack:1.9685\n",
      "Loss_L2Dist:0.0318, Loss_L1Dist:0.2342, AE_loss:0.0\n",
      "target_lab_score:0.0491, max_nontarget_lab_score:0.0523\n",
      "\n",
      "iter:0 const:[5.]\n",
      "Loss_Overall:2.5537, Loss_Attack:2.5356\n",
      "Loss_L2Dist:0.0049, Loss_L1Dist:0.1315, AE_loss:0.0\n",
      "target_lab_score:0.2089, max_nontarget_lab_score:-0.0983\n",
      "\n",
      "iter:500 const:[5.]\n",
      "Loss_Overall:2.5297, Loss_Attack:2.5035\n",
      "Loss_L2Dist:0.0142, Loss_L1Dist:0.1193, AE_loss:0.0\n",
      "target_lab_score:0.2061, max_nontarget_lab_score:-0.0946\n",
      "\n",
      "iter:0 const:[7.5]\n",
      "Loss_Overall:0.0955, Loss_Attack:0.0000\n",
      "Loss_L2Dist:0.0458, Loss_L1Dist:0.4973, AE_loss:0.0\n",
      "target_lab_score:-0.2575, max_nontarget_lab_score:0.3475\n",
      "\n",
      "iter:500 const:[7.5]\n",
      "Loss_Overall:6.2270, Loss_Attack:6.2256\n",
      "Loss_L2Dist:0.0002, Loss_L1Dist:0.0124, AE_loss:0.0\n",
      "target_lab_score:0.3740, max_nontarget_lab_score:-0.2561\n",
      "\n",
      "iter:0 const:[6.25]\n",
      "Loss_Overall:0.3702, Loss_Attack:0.3191\n",
      "Loss_L2Dist:0.0196, Loss_L1Dist:0.3144, AE_loss:0.0\n",
      "target_lab_score:-0.0243, max_nontarget_lab_score:0.1246\n",
      "\n",
      "iter:500 const:[6.25]\n",
      "Loss_Overall:1.6465, Loss_Attack:1.6025\n",
      "Loss_L2Dist:0.0224, Loss_L1Dist:0.2161, AE_loss:0.0\n",
      "target_lab_score:0.0802, max_nontarget_lab_score:0.0238\n",
      "\n",
      "iter:0 const:[5.625]\n",
      "Loss_Overall:1.6030, Loss_Attack:1.5699\n",
      "Loss_L2Dist:0.0108, Loss_L1Dist:0.2230, AE_loss:0.0\n",
      "target_lab_score:0.0923, max_nontarget_lab_score:0.0132\n",
      "\n",
      "iter:500 const:[5.625]\n",
      "Loss_Overall:1.7955, Loss_Attack:1.7445\n",
      "Loss_L2Dist:0.0328, Loss_L1Dist:0.1812, AE_loss:0.0\n",
      "target_lab_score:0.1090, max_nontarget_lab_score:-0.0012\n",
      "\n",
      "iter:0 const:[5.3125]\n",
      "Loss_Overall:2.1136, Loss_Attack:2.0884\n",
      "Loss_L2Dist:0.0075, Loss_L1Dist:0.1773, AE_loss:0.0\n",
      "target_lab_score:0.1506, max_nontarget_lab_score:-0.0426\n",
      "\n",
      "iter:500 const:[5.3125]\n",
      "Loss_Overall:2.8606, Loss_Attack:2.8401\n",
      "Loss_L2Dist:0.0095, Loss_L1Dist:0.1096, AE_loss:0.0\n",
      "target_lab_score:0.2232, max_nontarget_lab_score:-0.1114\n",
      "\n",
      "iter:0 const:[5.15625]\n",
      "Loss_Overall:2.3425, Loss_Attack:2.3209\n",
      "Loss_L2Dist:0.0061, Loss_L1Dist:0.1544, AE_loss:0.0\n",
      "target_lab_score:0.1797, max_nontarget_lab_score:-0.0704\n",
      "\n",
      "iter:500 const:[5.15625]\n",
      "Loss_Overall:4.0685, Loss_Attack:4.0654\n",
      "Loss_L2Dist:0.0004, Loss_L1Dist:0.0267, AE_loss:0.0\n",
      "target_lab_score:0.3526, max_nontarget_lab_score:-0.2358\n",
      "\n",
      "iter:0 const:[5.078125]\n",
      "Loss_Overall:2.4503, Loss_Attack:2.4305\n",
      "Loss_L2Dist:0.0055, Loss_L1Dist:0.1430, AE_loss:0.0\n",
      "target_lab_score:0.1943, max_nontarget_lab_score:-0.0843\n",
      "\n",
      "iter:500 const:[5.078125]\n",
      "Loss_Overall:2.4913, Loss_Attack:2.4634\n",
      "Loss_L2Dist:0.0155, Loss_L1Dist:0.1244, AE_loss:0.0\n",
      "target_lab_score:0.1981, max_nontarget_lab_score:-0.0869\n",
      "\n",
      "iter:0 const:[5.0390625]\n",
      "Loss_Overall:2.5025, Loss_Attack:2.4836\n",
      "Loss_L2Dist:0.0052, Loss_L1Dist:0.1373, AE_loss:0.0\n",
      "target_lab_score:0.2016, max_nontarget_lab_score:-0.0913\n",
      "\n",
      "iter:500 const:[5.0390625]\n",
      "Loss_Overall:0.4751, Loss_Attack:0.3833\n",
      "Loss_L2Dist:0.0661, Loss_L1Dist:0.2571, AE_loss:0.0\n",
      "target_lab_score:-0.0103, max_nontarget_lab_score:0.1136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some interesting user samples to try: 2344 449 1168 1272\n",
    "idx = 20\n",
    "\n",
    "X = xn_test[idx].reshape((1,) + xn_test[idx].shape)\n",
    "print(\"Computing PN for Sample:\", idx)\n",
    "print(\"Prediction made by the model:\", nn.predict_proba(X))\n",
    "print(\"Prediction probabilities:\", class_names[np.argmax(nn.predict_proba(X))])\n",
    "print(\"\")\n",
    "\n",
    "mymodel = KerasClassifier(nn)\n",
    "explainer = CEMExplainer(mymodel)\n",
    "\n",
    "arg_mode = 'PN' # Find pertinent negatives\n",
    "arg_max_iter = 1000 # Maximum number of iterations to search for the optimal PN for given parameter settings\n",
    "arg_init_const = 10.0 # Initial coefficient value for main loss term that encourages class change\n",
    "arg_b = 9 # No. of updates to the coefficient of the main loss term\n",
    "arg_kappa = 0.2 # Minimum confidence gap between the PNs (changed) class probability and original class' probability\n",
    "arg_beta = 1e-1 # Controls sparsity of the solution (L1 loss)\n",
    "arg_gamma = 100 # Controls how much to adhere to a (optionally trained) auto-encoder\n",
    "my_AE_model = None # Pointer to an auto-encoder\n",
    "arg_alpha = 0.01 # Penalizes L2 norm of the solution\n",
    "arg_threshold = 1. # Automatically turn off features <= arg_threshold if arg_threshold < 1\n",
    "arg_offset = 0.5 # the model assumes classifier trained on data normalized\n",
    "                # in [-arg_offset, arg_offset] range, where arg_offset is 0 or 0.5\n",
    "# Find PN for applicant 20\n",
    "(adv_pn, delta_pn, info_pn) = explainer.explain_instance(X, arg_mode, my_AE_model, arg_kappa, arg_b,\n",
    "                                                         arg_max_iter, arg_init_const, arg_beta, arg_gamma,\n",
    "                                                            arg_alpha, arg_threshold, arg_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6HnrLOfRwq1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Case_Study_1_as_a_task_to_be_completed 19059671.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
